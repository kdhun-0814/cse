import requests
from bs4 import BeautifulSoup
import json
import os
import datetime
import pytz
import firebase_admin
from firebase_admin import credentials, firestore
import re

# ==========================================
# 1. Firebase ì ‘ì†
# ==========================================
if not firebase_admin._apps:
    try:
        # 1. í™˜ê²½ë³€ìˆ˜ í™•ì¸ (GitHub Actions ìš©)
        firebase_key_json = os.environ.get('FIREBASE_KEY')
        
        if firebase_key_json:
            cred_dict = json.loads(firebase_key_json)
            cred = credentials.Certificate(cred_dict)
            print("ğŸ”¥ Firebase Connected via Env Var!")
        else:
            # 2. ë¡œì»¬ íŒŒì¼ í™•ì¸
            # ì ˆëŒ€ ê²½ë¡œ (ì‚¬ìš©ì ë¡œì»¬)
            key_path = "/Users/kdh/Desktop/MY_CSE/ai_server/serviceAccountKey.json"
            # ìƒëŒ€ ê²½ë¡œ (ai_server í´ë” ë‚´ ì‹¤í–‰ ì‹œ)
            if not os.path.exists(key_path):
                key_path = "serviceAccountKey.json"
                # ai_server ìƒìœ„ì—ì„œ ì‹¤í–‰ ì‹œ
                if not os.path.exists(key_path):
                     key_path = "ai_server/serviceAccountKey.json"

            cred = credentials.Certificate(key_path) if os.path.exists(key_path) else None
        
        if cred:
            firebase_admin.initialize_app(cred)
            print("ğŸ”¥ Firebase Connected!")
        else:
            print("âš ï¸ Warning: serviceAccountKey.json not found and FIREBASE_KEY not set.")
    except Exception as e:
        print(f"âš ï¸ Firebase Key Error: {e}")

db = firestore.client() if firebase_admin._apps else None

def scrape_and_save_menu():
    base_url = "https://www.gnu.ac.kr/main/ad/fm/foodmenu/selectFoodMenuView.do"
    
    # í•œêµ­ ì‹œê°„ ê¸°ì¤€
    kst = pytz.timezone("Asia/Seoul")
    today = datetime.datetime.now(tz=kst)
    # ì´ë²ˆì£¼ ì›”ìš”ì¼ ê³„ì‚° (ë‹¬ë ¥ì€ ë³´í†µ ì›”~ì¼ í˜¹ì€ í•´ë‹¹ ì£¼ í‘œì‹œ)
    start_of_week = today - datetime.timedelta(days=today.weekday())
    schDt = start_of_week.strftime("%Y-%m-%d")

    print(f"ğŸ“… Request Date (Week Start): {schDt}")

    cafeterias = [
        {"name": "ì¤‘ì•™ì‹ë‹¹", "seq": "5", "sysId": "main"},
        {"name": "êµë¬¸ì„¼1ì¸µ", "seq": "63", "sysId": "main"},
        {"name": "êµì§ì›ì‹ë‹¹", "seq": "4", "sysId": "main"},
        {"name": "ì¹ ì•”1ì‹ë‹¹", "seq": "8", "sysId": "cdorm"}, # ì¹ ì•”ì€ ì‹œìŠ¤í…œIDê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜ url íŒŒë¼ë¯¸í„°ë¡œ ì œì–´
    ]

    all_menus = {} # { "2024-01-22": { "ì¤‘ì•™ì‹ë‹¹": "...", "êµì§ì›": "..." } }

    for cafe in cafeterias:
        print(f"ğŸ” Scraping {cafe['name']}...")
        try:
            params = {
                "mi": "1341", # ë©”ë‰´ ID
                "restSeq": cafe["seq"],
                "schDt": schDt
            }
            if cafe['sysId'] == 'cdorm':
                # ì¹ ì•” ë“± ë‹¤ë¥¸ ìº í¼ìŠ¤ëŠ” URLì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. í™•ì¸ í•„ìš”. 
                # ì¼ë‹¨ ê³µí†µ URL ì‚¬ìš©í•´ë³´ê³  ì•ˆë˜ë©´ ì˜ˆì™¸ ì²˜ë¦¬.
                # ë³´í†µ ìº í¼ìŠ¤ë³„ ë„ë©”ì¸ì´ ë‹¤ë¦„ (www vs chilam ë“±)
                pass 

            response = requests.get(base_url, params=params, timeout=10)
            soup = BeautifulSoup(response.text, "html.parser")
            
            # í…Œì´ë¸” ì°¾ê¸°
            table = soup.select_one("div.cal_box table")
            if not table:
                table = soup.select_one("table") # Fallback to any table
            
            if not table:
                print(f"   âš ï¸ No table found for {cafe['name']}")
                continue

            # ë‚ ì§œ í—¤ë” íŒŒì‹±
            headers = table.select("thead th")
            date_map = {} # { index: "YYYY-MM-DD" }
            
            # ì •ê·œì‹ìœ¼ë¡œ ë‚ ì§œ ì¶”ì¶œ (2024.01.22 ë˜ëŠ” 01.22, êµ¬ë¶„ì ìœ ì—°í•˜ê²Œ)
            # YYYY.MM.DD or YYYY-MM-DD
            date_pattern_full = re.compile(r"(\d{4})[./-](\d{2})[./-](\d{2})")
            # MM.DD or MM-DD or MM/DD
            date_pattern_short = re.compile(r"(\d{2})[./-](\d{2})")

            for idx, th in enumerate(headers):
                text = th.get_text(strip=True)
                print(f"     Header[{idx}]: {text}")  # DEBUG

                match_full = date_pattern_full.search(text)
                if match_full:
                    # YYYY-MM-DD
                    date_str = f"{match_full.group(1)}-{match_full.group(2)}-{match_full.group(3)}"
                    date_map[idx] = date_str
                    continue
                
                match_short = date_pattern_short.search(text)
                if match_short:
                    # MM.DD -> YYYY-MM-DD (Use start_of_week year)
                    # ì£¼ì˜: ì—°ë„ê°€ ë°”ë€ŒëŠ” ì£¼ê°„(12ì›” ë§~1ì›” ì´ˆ) ì²˜ë¦¬ í•„ìš”í•  ìˆ˜ ìˆìŒ
                    # ì¼ë‹¨ ê°„ë‹¨íˆ start_of_week.year ì‚¬ìš©
                    year = start_of_week.year
                    # ë§Œì•½ start_of_weekê°€ 12ì›”ì´ê³  í˜„ì¬ ì›”ì´ 1ì›”ì´ë©´ year+1? (ë³µì¡í•˜ë¯€ë¡œ year ê·¸ëŒ€ë¡œ ì‚¬ìš©. ë³´í†µ í•™ì‹ì€ ë‹¹í•´ë…„ë„)
                    
                    date_str = f"{year}-{match_short.group(1)}-{match_short.group(2)}"
                    date_map[idx] = date_str
            # ë§Œì•½ ë‚ ì§œ íŒŒì‹±ì´ í•˜ë‚˜ë„ ì•ˆë˜ì—ˆê±°ë‚˜ ë„ˆë¬´ ì ìœ¼ë©´(1ê°œ ì´í•˜), ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ(ì›”~ì¼) í• ë‹¹ (Fallback)
            if len(date_map) <= 1:
                print("   âš ï¸ Date parsing insufficient. Using column index fallback (Mon-Sun).")
                # headers[0]ì€ 'êµ¬ë¶„'ì¼ í™•ë¥  ë†’ìŒ. 1ë¶€í„° ì›”ìš”ì¼.
                # start_of_weekëŠ” ì›”ìš”ì¼.
                
                for idx in range(1, len(headers)):
                    # idx=1 -> Mon (start_of_week + 0)
                    # idx=2 -> Tue (start_of_week + 1)
                    delta = idx - 1
                    target_date = start_of_week + datetime.timedelta(days=delta)
                    date_str = target_date.strftime("%Y-%m-%d")
                    date_map[idx] = date_str
                    print(f"     Fallback Header[{idx}] -> {date_str}")
            
            # ë©”ë‰´ íŒŒì‹± (tbody)
            rows = table.select("tbody tr")
            for tr in rows:
                th = tr.select_one("th")
                if not th: continue
                
                row_title = th.get_text(strip=True) # ì¡°ì‹, ì¤‘ì‹, ì„ì‹ ë“±
                
                # ë°ì´í„° ì…€
                tds = tr.select("td")
                
                for i, td in enumerate(tds):
                    # headers ì¸ë±ìŠ¤ì™€ ë§¤ì¹­ (td ì¸ë±ìŠ¤ + 1 == th ì¸ë±ìŠ¤, ë³´í†µ ì²« thê°€ row headerì´ë¯€ë¡œ)
                    # êµ¬ì¡°: thead th ê°œìˆ˜ì™€ tbody td ê°œìˆ˜ê°€ ë§ëŠ”ì§€ í™•ì¸
                    # ë³´í†µ thead ì²«ë²ˆì§¸ thëŠ” 'êµ¬ë¶„' ë“± ë¹ˆì¹¸.
                    
                    # date_mapì˜ í‚¤ëŠ” theadì˜ th ì¸ë±ìŠ¤.
                    # tbodyì˜ tdë‚´ìš©ì€ date_map[i+1] ë‚ ì§œì— í•´ë‹¹ (td 0ë²ˆ -> th 1ë²ˆ)
                    
                    date_key = date_map.get(i + 1)
                    if date_key:
                        content = td.get_text("\n", strip=True)
                        if content:
                            if date_key not in all_menus:
                                all_menus[date_key] = {}
                            
                            # ê¸°ì¡´ ë‚´ìš© ë³‘í•© (ì¡°ì‹, ì¤‘ì‹ ë“± êµ¬ë¶„)
                            existing = all_menus[date_key].get(cafe['name'], "")
                            if existing:
                                existing += f"\n\n[{row_title}]\n{content}"
                            else:
                                existing = f"[{row_title}]\n{content}"
                            
                            all_menus[date_key][cafe['name']] = existing

        except Exception as e:
            print(f"   âŒ Error: {e}")

    # Firestore ì €ì¥
    if db and all_menus:
        print(f"ğŸ’¾ Saving {len(all_menus)} dates to Firestore...")
        batch = db.batch()
        
        for date_key, menus in all_menus.items():
            doc_ref = db.collection('cafeteria_menus').document(date_key)
            batch.set(doc_ref, {
                "date": date_key,
                "menus": menus,
                "updated_at": firestore.SERVER_TIMESTAMP
            }, merge=True)
            
        batch.commit()
        print("âœ… Menu Saved Successfully!")
    else:
        print("âš ï¸ No data to save or DB not connected.")
        # print(json.dumps(all_menus, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    scrape_and_save_menu()
